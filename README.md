# ðŸ©º Visual Symptom Checker

A multimodal AI-powered health assistant that helps users analyze visible symptoms (e.g., rashes, swelling, redness) using both uploaded images and self-reported symptoms. Built with **Chainlit** for the frontend and **MongoDB** for persistent case tracking.

---

## ðŸš€ Features

- ðŸ–¼ Upload images of visible symptoms (e.g., skin rash)
- ðŸ“ Describe additional symptoms (e.g., itching, pain)
- ðŸ§  Uses GPT-4 Vision (or LLaVA) to analyze both
- ðŸ©¹ Suggests likely conditions, severity, and treatment advice
- ðŸ—ƒ Saves all cases to MongoDB for traceability

---

## ðŸ§± Tech Stack

- **Frontend**: [Chainlit](https://docs.chainlit.io) (LLM-native UI)
- **LLM Backend**: OpenAI GPT-4V or LLaVA
- **Database**: MongoDB (for storing records)
- **Image Handling**: Pillow + Base64 encoding

---

## ðŸ–¼ Sample Use Case

Upload a photo of a rash and type:

> "Itâ€™s been itchy and red for 3 days with some swelling."

The assistant replies with:
- ðŸ¦  Possible diagnosis: Contact dermatitis, Eczema...
- ðŸš¨ Severity: Moderate
- ðŸ’Š Recommendations: Apply hydrocortisone, avoid irritants...

---

## ðŸ§ª Run Locally

### 1. Clone this repo

```bash
[git clone https://github.com/patla001/multimodal-rag-chatbot.git](https://github.com/patla001/multimodal-rag-chatbot.git)
cd multimodal-rag-chatbot

```
